{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaea2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import math as math \n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import f_regression \n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn import neighbors \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "955c1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Left-Lateral-Ventricle</th>\n",
       "      <th>Left-Inf-Lat-Vent</th>\n",
       "      <th>Left-Cerebellum-White-Matter</th>\n",
       "      <th>Left-Cerebellum-Cortex</th>\n",
       "      <th>Left-Thalamus</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Left-Pallidum</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_frontalpole_thickness</th>\n",
       "      <th>rh_temporalpole_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>BrainSegVolNotVent.2</th>\n",
       "      <th>eTIV.1</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4.226000e+03</td>\n",
       "      <td>4.226000e+03</td>\n",
       "      <td>4226.000000</td>\n",
       "      <td>4226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2113.500000</td>\n",
       "      <td>13370.040795</td>\n",
       "      <td>574.849716</td>\n",
       "      <td>14646.696711</td>\n",
       "      <td>52002.811571</td>\n",
       "      <td>7164.947539</td>\n",
       "      <td>3337.653526</td>\n",
       "      <td>4505.158755</td>\n",
       "      <td>1958.214458</td>\n",
       "      <td>1418.947373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.429779</td>\n",
       "      <td>2.684327</td>\n",
       "      <td>3.555803</td>\n",
       "      <td>2.288283</td>\n",
       "      <td>2.846123</td>\n",
       "      <td>2.372266</td>\n",
       "      <td>1.085468e+06</td>\n",
       "      <td>1.514925e+06</td>\n",
       "      <td>58.374586</td>\n",
       "      <td>4.533838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1220.085448</td>\n",
       "      <td>9194.928348</td>\n",
       "      <td>594.590387</td>\n",
       "      <td>2622.868798</td>\n",
       "      <td>6378.435917</td>\n",
       "      <td>1207.229615</td>\n",
       "      <td>502.352001</td>\n",
       "      <td>713.658580</td>\n",
       "      <td>287.139826</td>\n",
       "      <td>635.143286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185543</td>\n",
       "      <td>0.275245</td>\n",
       "      <td>0.332094</td>\n",
       "      <td>0.269851</td>\n",
       "      <td>0.195038</td>\n",
       "      <td>0.146944</td>\n",
       "      <td>1.248881e+05</td>\n",
       "      <td>1.651798e+05</td>\n",
       "      <td>20.064099</td>\n",
       "      <td>3.057928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2204.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6920.100000</td>\n",
       "      <td>29911.800000</td>\n",
       "      <td>4145.400000</td>\n",
       "      <td>1035.600000</td>\n",
       "      <td>2294.000000</td>\n",
       "      <td>851.900000</td>\n",
       "      <td>39.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>1.176000</td>\n",
       "      <td>1.533000</td>\n",
       "      <td>1.483290</td>\n",
       "      <td>6.279600e+05</td>\n",
       "      <td>8.329815e+05</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1057.250000</td>\n",
       "      <td>7031.625000</td>\n",
       "      <td>243.200000</td>\n",
       "      <td>12909.875000</td>\n",
       "      <td>47359.675000</td>\n",
       "      <td>6239.425000</td>\n",
       "      <td>2984.500000</td>\n",
       "      <td>4008.125000</td>\n",
       "      <td>1764.700000</td>\n",
       "      <td>941.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.309000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>2.105000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.274935</td>\n",
       "      <td>9.957585e+05</td>\n",
       "      <td>1.404471e+06</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2113.500000</td>\n",
       "      <td>10669.950000</td>\n",
       "      <td>385.800000</td>\n",
       "      <td>14277.000000</td>\n",
       "      <td>51333.650000</td>\n",
       "      <td>7032.150000</td>\n",
       "      <td>3294.050000</td>\n",
       "      <td>4438.100000</td>\n",
       "      <td>1940.100000</td>\n",
       "      <td>1225.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.440500</td>\n",
       "      <td>2.685000</td>\n",
       "      <td>3.586500</td>\n",
       "      <td>2.297000</td>\n",
       "      <td>2.851000</td>\n",
       "      <td>2.383375</td>\n",
       "      <td>1.075919e+06</td>\n",
       "      <td>1.511767e+06</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3169.750000</td>\n",
       "      <td>17332.650000</td>\n",
       "      <td>720.825000</td>\n",
       "      <td>15959.725000</td>\n",
       "      <td>56287.775000</td>\n",
       "      <td>7977.400000</td>\n",
       "      <td>3655.125000</td>\n",
       "      <td>4963.025000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>1780.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.562750</td>\n",
       "      <td>2.851000</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>2.476000</td>\n",
       "      <td>2.975000</td>\n",
       "      <td>2.483142</td>\n",
       "      <td>1.168888e+06</td>\n",
       "      <td>1.625445e+06</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4226.000000</td>\n",
       "      <td>79812.500000</td>\n",
       "      <td>7533.800000</td>\n",
       "      <td>35042.500000</td>\n",
       "      <td>79948.200000</td>\n",
       "      <td>13008.300000</td>\n",
       "      <td>6018.000000</td>\n",
       "      <td>8446.100000</td>\n",
       "      <td>4357.700000</td>\n",
       "      <td>4461.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.996000</td>\n",
       "      <td>3.928000</td>\n",
       "      <td>4.487000</td>\n",
       "      <td>3.123000</td>\n",
       "      <td>3.482000</td>\n",
       "      <td>2.803730</td>\n",
       "      <td>1.545129e+06</td>\n",
       "      <td>2.075213e+06</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              S.No  Left-Lateral-Ventricle  Left-Inf-Lat-Vent  \\\n",
       "count  4226.000000             4226.000000        4226.000000   \n",
       "mean   2113.500000            13370.040795         574.849716   \n",
       "std    1220.085448             9194.928348         594.590387   \n",
       "min       1.000000             2204.100000           0.000000   \n",
       "25%    1057.250000             7031.625000         243.200000   \n",
       "50%    2113.500000            10669.950000         385.800000   \n",
       "75%    3169.750000            17332.650000         720.825000   \n",
       "max    4226.000000            79812.500000        7533.800000   \n",
       "\n",
       "       Left-Cerebellum-White-Matter  Left-Cerebellum-Cortex  Left-Thalamus  \\\n",
       "count                   4226.000000             4226.000000    4226.000000   \n",
       "mean                   14646.696711            52002.811571    7164.947539   \n",
       "std                     2622.868798             6378.435917    1207.229615   \n",
       "min                     6920.100000            29911.800000    4145.400000   \n",
       "25%                    12909.875000            47359.675000    6239.425000   \n",
       "50%                    14277.000000            51333.650000    7032.150000   \n",
       "75%                    15959.725000            56287.775000    7977.400000   \n",
       "max                    35042.500000            79948.200000   13008.300000   \n",
       "\n",
       "       Left-Caudate  Left-Putamen  Left-Pallidum  3rd-Ventricle  ...  \\\n",
       "count   4226.000000   4226.000000    4226.000000    4226.000000  ...   \n",
       "mean    3337.653526   4505.158755    1958.214458    1418.947373  ...   \n",
       "std      502.352001    713.658580     287.139826     635.143286  ...   \n",
       "min     1035.600000   2294.000000     851.900000      39.700000  ...   \n",
       "25%     2984.500000   4008.125000    1764.700000     941.825000  ...   \n",
       "50%     3294.050000   4438.100000    1940.100000    1225.450000  ...   \n",
       "75%     3655.125000   4963.025000    2128.000000    1780.225000  ...   \n",
       "max     6018.000000   8446.100000    4357.700000    4461.600000  ...   \n",
       "\n",
       "       rh_supramarginal_thickness  rh_frontalpole_thickness  \\\n",
       "count                 4226.000000               4226.000000   \n",
       "mean                     2.429779                  2.684327   \n",
       "std                      0.185543                  0.275245   \n",
       "min                      1.345000                  1.655000   \n",
       "25%                      2.309000                  2.510000   \n",
       "50%                      2.440500                  2.685000   \n",
       "75%                      2.562750                  2.851000   \n",
       "max                      2.996000                  3.928000   \n",
       "\n",
       "       rh_temporalpole_thickness  rh_transversetemporal_thickness  \\\n",
       "count                4226.000000                      4226.000000   \n",
       "mean                    3.555803                         2.288283   \n",
       "std                     0.332094                         0.269851   \n",
       "min                     1.940000                         1.176000   \n",
       "25%                     3.360000                         2.105000   \n",
       "50%                     3.586500                         2.297000   \n",
       "75%                     3.790000                         2.476000   \n",
       "max                     4.487000                         3.123000   \n",
       "\n",
       "       rh_insula_thickness  rh_MeanThickness_thickness  BrainSegVolNotVent.2  \\\n",
       "count          4226.000000                 4226.000000          4.226000e+03   \n",
       "mean              2.846123                    2.372266          1.085468e+06   \n",
       "std               0.195038                    0.146944          1.248881e+05   \n",
       "min               1.533000                    1.483290          6.279600e+05   \n",
       "25%               2.720000                    2.274935          9.957585e+05   \n",
       "50%               2.851000                    2.383375          1.075919e+06   \n",
       "75%               2.975000                    2.483142          1.168888e+06   \n",
       "max               3.482000                    2.803730          1.545129e+06   \n",
       "\n",
       "             eTIV.1          Age      dataset  \n",
       "count  4.226000e+03  4226.000000  4226.000000  \n",
       "mean   1.514925e+06    58.374586     4.533838  \n",
       "std    1.651798e+05    20.064099     3.057928  \n",
       "min    8.329815e+05    18.000000     1.000000  \n",
       "25%    1.404471e+06    43.000000     1.000000  \n",
       "50%    1.511767e+06    61.000000     4.000000  \n",
       "75%    1.625445e+06    76.000000     8.000000  \n",
       "max    2.075213e+06    96.000000     9.000000  \n",
       "\n",
       "[8 rows x 141 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../../data_sets/Volumetric_features.xlsx')\n",
    "data.head()\n",
    "\n",
    "\n",
    "data_features = pd.DataFrame(data, columns = data.columns[:-1])\n",
    "data_features= data.drop(['S.No','Age'], axis=1)\n",
    "\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91b9729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4226, 141)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDd = data.copy()\n",
    "dataDd.drop_duplicates(inplace=True) #this function get rid of the duplicate if there are any in the dataset \n",
    "dataDd.shape #this function returns the shape of the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c841e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Left-Lateral-Ventricle</th>\n",
       "      <th>Left-Inf-Lat-Vent</th>\n",
       "      <th>Left-Cerebellum-White-Matter</th>\n",
       "      <th>Left-Cerebellum-Cortex</th>\n",
       "      <th>Left-Thalamus</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Left-Pallidum</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_frontalpole_thickness</th>\n",
       "      <th>rh_temporalpole_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>BrainSegVolNotVent.2</th>\n",
       "      <th>eTIV.1</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22916.9</td>\n",
       "      <td>982.7</td>\n",
       "      <td>15196.7</td>\n",
       "      <td>55796.4</td>\n",
       "      <td>6855.5</td>\n",
       "      <td>2956.4</td>\n",
       "      <td>4240.7</td>\n",
       "      <td>2223.9</td>\n",
       "      <td>2034.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408</td>\n",
       "      <td>2.629</td>\n",
       "      <td>3.519</td>\n",
       "      <td>2.009</td>\n",
       "      <td>2.825</td>\n",
       "      <td>2.33635</td>\n",
       "      <td>1093846</td>\n",
       "      <td>1619602.965</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22953.2</td>\n",
       "      <td>984.5</td>\n",
       "      <td>15289.7</td>\n",
       "      <td>55778.6</td>\n",
       "      <td>6835.1</td>\n",
       "      <td>3064.2</td>\n",
       "      <td>4498.6</td>\n",
       "      <td>2354.1</td>\n",
       "      <td>1927.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417</td>\n",
       "      <td>2.640</td>\n",
       "      <td>3.488</td>\n",
       "      <td>2.111</td>\n",
       "      <td>2.720</td>\n",
       "      <td>2.34202</td>\n",
       "      <td>1099876</td>\n",
       "      <td>1624755.130</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23320.4</td>\n",
       "      <td>1062.1</td>\n",
       "      <td>15382.1</td>\n",
       "      <td>55551.2</td>\n",
       "      <td>7566.0</td>\n",
       "      <td>3231.7</td>\n",
       "      <td>4456.2</td>\n",
       "      <td>1995.4</td>\n",
       "      <td>2064.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.374</td>\n",
       "      <td>2.601</td>\n",
       "      <td>3.342</td>\n",
       "      <td>2.146</td>\n",
       "      <td>2.684</td>\n",
       "      <td>2.31982</td>\n",
       "      <td>1097999</td>\n",
       "      <td>1622609.518</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24360.0</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>14805.4</td>\n",
       "      <td>54041.8</td>\n",
       "      <td>8004.6</td>\n",
       "      <td>3137.3</td>\n",
       "      <td>4262.2</td>\n",
       "      <td>1983.4</td>\n",
       "      <td>2017.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.366</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.056</td>\n",
       "      <td>2.700</td>\n",
       "      <td>2.29215</td>\n",
       "      <td>1070117</td>\n",
       "      <td>1583854.236</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25769.4</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>16331.1</td>\n",
       "      <td>54108.6</td>\n",
       "      <td>6677.4</td>\n",
       "      <td>2964.4</td>\n",
       "      <td>4204.6</td>\n",
       "      <td>2409.7</td>\n",
       "      <td>2251.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.555</td>\n",
       "      <td>3.450</td>\n",
       "      <td>2.052</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.30397</td>\n",
       "      <td>1075926</td>\n",
       "      <td>1617375.362</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No  Left-Lateral-Ventricle  Left-Inf-Lat-Vent  \\\n",
       "0     1                 22916.9              982.7   \n",
       "1     2                 22953.2              984.5   \n",
       "2     3                 23320.4             1062.1   \n",
       "3     4                 24360.0             1000.5   \n",
       "4     5                 25769.4             1124.4   \n",
       "\n",
       "   Left-Cerebellum-White-Matter  Left-Cerebellum-Cortex  Left-Thalamus  \\\n",
       "0                       15196.7                 55796.4         6855.5   \n",
       "1                       15289.7                 55778.6         6835.1   \n",
       "2                       15382.1                 55551.2         7566.0   \n",
       "3                       14805.4                 54041.8         8004.6   \n",
       "4                       16331.1                 54108.6         6677.4   \n",
       "\n",
       "   Left-Caudate  Left-Putamen  Left-Pallidum  3rd-Ventricle  ...  \\\n",
       "0        2956.4        4240.7         2223.9         2034.4  ...   \n",
       "1        3064.2        4498.6         2354.1         1927.1  ...   \n",
       "2        3231.7        4456.2         1995.4         2064.7  ...   \n",
       "3        3137.3        4262.2         1983.4         2017.7  ...   \n",
       "4        2964.4        4204.6         2409.7         2251.8  ...   \n",
       "\n",
       "   rh_supramarginal_thickness  rh_frontalpole_thickness  \\\n",
       "0                       2.408                     2.629   \n",
       "1                       2.417                     2.640   \n",
       "2                       2.374                     2.601   \n",
       "3                       2.366                     2.639   \n",
       "4                       2.381                     2.555   \n",
       "\n",
       "   rh_temporalpole_thickness  rh_transversetemporal_thickness  \\\n",
       "0                      3.519                            2.009   \n",
       "1                      3.488                            2.111   \n",
       "2                      3.342                            2.146   \n",
       "3                      3.361                            2.056   \n",
       "4                      3.450                            2.052   \n",
       "\n",
       "   rh_insula_thickness  rh_MeanThickness_thickness  BrainSegVolNotVent.2  \\\n",
       "0                2.825                     2.33635               1093846   \n",
       "1                2.720                     2.34202               1099876   \n",
       "2                2.684                     2.31982               1097999   \n",
       "3                2.700                     2.29215               1070117   \n",
       "4                2.574                     2.30397               1075926   \n",
       "\n",
       "        eTIV.1  Age  dataset  \n",
       "0  1619602.965   85        1  \n",
       "1  1624755.130   85        1  \n",
       "2  1622609.518   86        1  \n",
       "3  1583854.236   87        1  \n",
       "4  1617375.362   89        1  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=dataDd #replacing health data to healthDd data \n",
    "del dataDd #deleting healthDd  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed2c2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       rh_insula_thickness  rhCerebralWhiteMatterVol      S.No  \\\n",
      "0                2.116693                  1.364192  1.509742   \n",
      "1                1.781763                  1.577276  1.751911   \n",
      "2                2.423064                  1.424486  1.583686   \n",
      "3                4.657487                  1.366376  1.174583   \n",
      "4                3.795704                  1.701513  2.226929   \n",
      "...                   ...                       ...       ...   \n",
      "4221             3.332053                  2.220377  0.517893   \n",
      "4222             4.258130                 -2.535943  1.742708   \n",
      "4223             7.826457                  2.169779  3.995974   \n",
      "4224            -0.702317                  2.439427  7.148804   \n",
      "4225            -2.373678                 -3.566135  2.435557   \n",
      "\n",
      "      lh_lateraloccipital_thickness  rhSurfaceHoles  Optic-Chiasm  \\\n",
      "0                         -2.002547       -1.880995      2.278606   \n",
      "1                         -1.118207       -1.487249      2.077501   \n",
      "2                         -1.542398       -1.247237      1.774430   \n",
      "3                         -0.637339       -1.459941      2.256621   \n",
      "4                         -1.242365       -1.389589      2.822711   \n",
      "...                             ...             ...           ...   \n",
      "4221                       1.504443        0.767337     -0.088016   \n",
      "4222                      -2.389864        1.916595      0.225210   \n",
      "4223                      -1.862912        1.557314      2.806352   \n",
      "4224                       0.140688        2.688875      5.133186   \n",
      "4225                      -2.369929        1.958568      2.433267   \n",
      "\n",
      "      rh_bankssts_thickness  Optic-Chiasm  Right-Thalamus  \\\n",
      "0                 -1.646300     -0.011330       -0.459902   \n",
      "1                 -1.812250     -0.369204       -0.918849   \n",
      "2                 -2.453779     -0.634583       -1.262895   \n",
      "3                 -1.237767     -0.935250       -1.093537   \n",
      "4                 -1.682757     -0.278114       -0.691466   \n",
      "...                     ...           ...             ...   \n",
      "4221               0.286235     -2.292263       -0.612192   \n",
      "4222               0.947909     -2.434125        0.599141   \n",
      "4223               1.449355      0.581763        1.852462   \n",
      "4224               1.888644      0.901401        4.562703   \n",
      "4225               1.592052     -0.545859        2.211255   \n",
      "\n",
      "      lh_middletemporal_thickness  ...  lh_precuneus_thickness  \\\n",
      "0                        1.800872  ...               -0.422278   \n",
      "1                        1.980609  ...                0.169302   \n",
      "2                        1.761288  ...               -0.032230   \n",
      "3                        1.561650  ...               -0.323545   \n",
      "4                        1.798995  ...               -0.096144   \n",
      "...                           ...  ...                     ...   \n",
      "4221                    -0.860856  ...                1.112460   \n",
      "4222                    -0.285508  ...                0.383121   \n",
      "4223                    -0.117440  ...                0.145134   \n",
      "4224                     1.176732  ...               -0.573420   \n",
      "4225                     0.199773  ...                0.401053   \n",
      "\n",
      "      Right-choroid-plexus  Right-choroid-plexus  Right-WM-hypointensities  \\\n",
      "0                -0.105162              0.747861                  0.247528   \n",
      "1                -0.027182              0.774726                  0.186905   \n",
      "2                 0.338045              0.601288                  0.000853   \n",
      "3                 0.429014              0.555494                 -0.550396   \n",
      "4                -0.116848              0.491955                 -0.401563   \n",
      "...                    ...                   ...                       ...   \n",
      "4221             -0.206237             -0.863194                 -0.447822   \n",
      "4222             -0.238162              0.941073                  0.203122   \n",
      "4223             -0.910926             -1.770552                 -1.686230   \n",
      "4224              0.064293             -1.071109                 -1.189629   \n",
      "4225             -1.416574             -0.530154                 -0.647105   \n",
      "\n",
      "      rh_precuneus_thickness  Left-Cerebellum-White-Matter  \\\n",
      "0                  -1.572648                      0.524016   \n",
      "1                  -1.660712                      0.650243   \n",
      "2                  -1.678563                      0.455414   \n",
      "3                  -1.578926                      0.621149   \n",
      "4                  -1.404124                      0.752122   \n",
      "...                      ...                           ...   \n",
      "4221                0.868115                     -1.372714   \n",
      "4222                0.202414                      0.366696   \n",
      "4223                1.453537                      1.921877   \n",
      "4224                0.067078                      0.705501   \n",
      "4225               -0.975551                      0.694621   \n",
      "\n",
      "      lh_precuneus_thickness  lh_temporalpole_thickness  \\\n",
      "0                  -0.011988                   0.307543   \n",
      "1                   0.270660                   0.270478   \n",
      "2                   0.357245                  -0.083775   \n",
      "3                   0.086465                   0.583232   \n",
      "4                  -0.515622                  -0.075725   \n",
      "...                      ...                        ...   \n",
      "4221                1.073146                   1.023793   \n",
      "4222               -0.947024                  -0.128045   \n",
      "4223               -1.334597                   0.307933   \n",
      "4224                0.889338                  -1.990343   \n",
      "4225                0.678391                  -0.197635   \n",
      "\n",
      "      rh_frontalpole_thickness  rh_bankssts_thickness  \n",
      "0                    -0.426805              -0.229143  \n",
      "1                    -0.390153               0.055337  \n",
      "2                    -0.142788              -0.142963  \n",
      "3                    -0.038076               0.244896  \n",
      "4                    -0.586110               0.035086  \n",
      "...                        ...                    ...  \n",
      "4221                  0.015771               0.244765  \n",
      "4222                  0.964633               0.603608  \n",
      "4223                  0.058994               0.807395  \n",
      "4224                  0.839377              -1.093018  \n",
      "4225                 -0.678130              -0.635135  \n",
      "\n",
      "[4226 rows x 30 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rhCerebralWhiteMatterVol</th>\n",
       "      <th>S.No</th>\n",
       "      <th>lh_lateraloccipital_thickness</th>\n",
       "      <th>rhSurfaceHoles</th>\n",
       "      <th>Optic-Chiasm</th>\n",
       "      <th>rh_bankssts_thickness</th>\n",
       "      <th>Optic-Chiasm</th>\n",
       "      <th>Right-Thalamus</th>\n",
       "      <th>lh_middletemporal_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>lh_precuneus_thickness</th>\n",
       "      <th>Right-choroid-plexus</th>\n",
       "      <th>Right-choroid-plexus</th>\n",
       "      <th>Right-WM-hypointensities</th>\n",
       "      <th>rh_precuneus_thickness</th>\n",
       "      <th>Left-Cerebellum-White-Matter</th>\n",
       "      <th>lh_precuneus_thickness</th>\n",
       "      <th>lh_temporalpole_thickness</th>\n",
       "      <th>rh_frontalpole_thickness</th>\n",
       "      <th>rh_bankssts_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.116693</td>\n",
       "      <td>1.364192</td>\n",
       "      <td>1.509742</td>\n",
       "      <td>-2.002547</td>\n",
       "      <td>-1.880995</td>\n",
       "      <td>2.278606</td>\n",
       "      <td>-1.646300</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.459902</td>\n",
       "      <td>1.800872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422278</td>\n",
       "      <td>-0.105162</td>\n",
       "      <td>0.747861</td>\n",
       "      <td>0.247528</td>\n",
       "      <td>-1.572648</td>\n",
       "      <td>0.524016</td>\n",
       "      <td>-0.011988</td>\n",
       "      <td>0.307543</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.229143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.781763</td>\n",
       "      <td>1.577276</td>\n",
       "      <td>1.751911</td>\n",
       "      <td>-1.118207</td>\n",
       "      <td>-1.487249</td>\n",
       "      <td>2.077501</td>\n",
       "      <td>-1.812250</td>\n",
       "      <td>-0.369204</td>\n",
       "      <td>-0.918849</td>\n",
       "      <td>1.980609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169302</td>\n",
       "      <td>-0.027182</td>\n",
       "      <td>0.774726</td>\n",
       "      <td>0.186905</td>\n",
       "      <td>-1.660712</td>\n",
       "      <td>0.650243</td>\n",
       "      <td>0.270660</td>\n",
       "      <td>0.270478</td>\n",
       "      <td>-0.390153</td>\n",
       "      <td>0.055337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.423064</td>\n",
       "      <td>1.424486</td>\n",
       "      <td>1.583686</td>\n",
       "      <td>-1.542398</td>\n",
       "      <td>-1.247237</td>\n",
       "      <td>1.774430</td>\n",
       "      <td>-2.453779</td>\n",
       "      <td>-0.634583</td>\n",
       "      <td>-1.262895</td>\n",
       "      <td>1.761288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032230</td>\n",
       "      <td>0.338045</td>\n",
       "      <td>0.601288</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-1.678563</td>\n",
       "      <td>0.455414</td>\n",
       "      <td>0.357245</td>\n",
       "      <td>-0.083775</td>\n",
       "      <td>-0.142788</td>\n",
       "      <td>-0.142963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.657487</td>\n",
       "      <td>1.366376</td>\n",
       "      <td>1.174583</td>\n",
       "      <td>-0.637339</td>\n",
       "      <td>-1.459941</td>\n",
       "      <td>2.256621</td>\n",
       "      <td>-1.237767</td>\n",
       "      <td>-0.935250</td>\n",
       "      <td>-1.093537</td>\n",
       "      <td>1.561650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323545</td>\n",
       "      <td>0.429014</td>\n",
       "      <td>0.555494</td>\n",
       "      <td>-0.550396</td>\n",
       "      <td>-1.578926</td>\n",
       "      <td>0.621149</td>\n",
       "      <td>0.086465</td>\n",
       "      <td>0.583232</td>\n",
       "      <td>-0.038076</td>\n",
       "      <td>0.244896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.795704</td>\n",
       "      <td>1.701513</td>\n",
       "      <td>2.226929</td>\n",
       "      <td>-1.242365</td>\n",
       "      <td>-1.389589</td>\n",
       "      <td>2.822711</td>\n",
       "      <td>-1.682757</td>\n",
       "      <td>-0.278114</td>\n",
       "      <td>-0.691466</td>\n",
       "      <td>1.798995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096144</td>\n",
       "      <td>-0.116848</td>\n",
       "      <td>0.491955</td>\n",
       "      <td>-0.401563</td>\n",
       "      <td>-1.404124</td>\n",
       "      <td>0.752122</td>\n",
       "      <td>-0.515622</td>\n",
       "      <td>-0.075725</td>\n",
       "      <td>-0.586110</td>\n",
       "      <td>0.035086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rh_insula_thickness  rhCerebralWhiteMatterVol      S.No  \\\n",
       "0             2.116693                  1.364192  1.509742   \n",
       "1             1.781763                  1.577276  1.751911   \n",
       "2             2.423064                  1.424486  1.583686   \n",
       "3             4.657487                  1.366376  1.174583   \n",
       "4             3.795704                  1.701513  2.226929   \n",
       "\n",
       "   lh_lateraloccipital_thickness  rhSurfaceHoles  Optic-Chiasm  \\\n",
       "0                      -2.002547       -1.880995      2.278606   \n",
       "1                      -1.118207       -1.487249      2.077501   \n",
       "2                      -1.542398       -1.247237      1.774430   \n",
       "3                      -0.637339       -1.459941      2.256621   \n",
       "4                      -1.242365       -1.389589      2.822711   \n",
       "\n",
       "   rh_bankssts_thickness  Optic-Chiasm  Right-Thalamus  \\\n",
       "0              -1.646300     -0.011330       -0.459902   \n",
       "1              -1.812250     -0.369204       -0.918849   \n",
       "2              -2.453779     -0.634583       -1.262895   \n",
       "3              -1.237767     -0.935250       -1.093537   \n",
       "4              -1.682757     -0.278114       -0.691466   \n",
       "\n",
       "   lh_middletemporal_thickness  ...  lh_precuneus_thickness  \\\n",
       "0                     1.800872  ...               -0.422278   \n",
       "1                     1.980609  ...                0.169302   \n",
       "2                     1.761288  ...               -0.032230   \n",
       "3                     1.561650  ...               -0.323545   \n",
       "4                     1.798995  ...               -0.096144   \n",
       "\n",
       "   Right-choroid-plexus  Right-choroid-plexus  Right-WM-hypointensities  \\\n",
       "0             -0.105162              0.747861                  0.247528   \n",
       "1             -0.027182              0.774726                  0.186905   \n",
       "2              0.338045              0.601288                  0.000853   \n",
       "3              0.429014              0.555494                 -0.550396   \n",
       "4             -0.116848              0.491955                 -0.401563   \n",
       "\n",
       "   rh_precuneus_thickness  Left-Cerebellum-White-Matter  \\\n",
       "0               -1.572648                      0.524016   \n",
       "1               -1.660712                      0.650243   \n",
       "2               -1.678563                      0.455414   \n",
       "3               -1.578926                      0.621149   \n",
       "4               -1.404124                      0.752122   \n",
       "\n",
       "   lh_precuneus_thickness  lh_temporalpole_thickness  \\\n",
       "0               -0.011988                   0.307543   \n",
       "1                0.270660                   0.270478   \n",
       "2                0.357245                  -0.083775   \n",
       "3                0.086465                   0.583232   \n",
       "4               -0.515622                  -0.075725   \n",
       "\n",
       "   rh_frontalpole_thickness  rh_bankssts_thickness  \n",
       "0                 -0.426805              -0.229143  \n",
       "1                 -0.390153               0.055337  \n",
       "2                 -0.142788              -0.142963  \n",
       "3                 -0.038076               0.244896  \n",
       "4                 -0.586110               0.035086  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(data_features)\n",
    "n = 30\n",
    "pca = PCA(n_components=n)\n",
    "pca_dataF = pca.fit_transform(x)\n",
    "\n",
    "labels = data.columns.values.tolist()\n",
    "label_index = [np.abs(pca.components_[i]).argmax() for i in range(n)]\n",
    "columns = [labels[label_index[i]] for i in range(n)]\n",
    "\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=columns)\n",
    "print(pca_df.head)\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a78bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_df, data['Age'], test_size=0.20, random_state=33)\n",
    "\n",
    "\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.25, random_state=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c71cd236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 9.135768394116797\n",
      "RMSE value for k=  2 is: 7.90226263275153\n",
      "RMSE value for k=  3 is: 7.343367920164525\n",
      "RMSE value for k=  4 is: 7.189381419056805\n",
      "RMSE value for k=  5 is: 7.019675851248673\n",
      "RMSE value for k=  6 is: 7.059495590155247\n",
      "RMSE value for k=  7 is: 6.955687898913578\n",
      "RMSE value for k=  8 is: 6.863686016356814\n",
      "RMSE value for k=  9 is: 6.928909248090491\n",
      "RMSE value for k=  10 is: 6.927294252475304\n",
      "RMSE value for k=  11 is: 7.0140366272355665\n",
      "RMSE value for k=  12 is: 7.07952404045731\n",
      "RMSE value for k=  13 is: 7.130026515133649\n",
      "RMSE value for k=  14 is: 7.089891223878036\n",
      "RMSE value for k=  15 is: 7.157847433007625\n",
      "RMSE value for k=  16 is: 7.165717608470182\n",
      "RMSE value for k=  17 is: 7.0937399472068075\n",
      "RMSE value for k=  18 is: 7.067140409077205\n",
      "RMSE value for k=  19 is: 7.105126152638438\n",
      "RMSE value for k=  20 is: 7.18400591854822\n"
     ]
    }
   ],
   "source": [
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(X_train, y_train)  #fit the model\n",
    "    pred=model.predict(X_test) #make prediction on test set\n",
    "    error = np.sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883dcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d59f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve = pd.DataFrame(rmse_val) #elbow curve \n",
    "curve.plot()\n",
    "\n",
    "#From the plot K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8be362cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = neighbors.KNeighborsRegressor(10)\n",
    "\n",
    "kNN.fit(X_train,y_train)\n",
    "y_pred = kNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2b21c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.8789098904349077\n",
      "Max Error: 19.700000000000003\n",
      "Mean absolute error: 5.180660377358492\n",
      "Mean squared error: 47.98740566037737\n",
      "Root Mean Squared Error: 6.927294252475304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_qerror = metrics.mean_squared_error(y_test, y_pred)\n",
    "root_mean_qerror = np.sqrt(mean_qerror)\n",
    "\n",
    "\n",
    "print(\"R squared: \" + str(metrics.explained_variance_score(y_test, y_pred)))\n",
    "print(\"Max Error: \" + str(metrics.max_error(y_test, y_pred)))\n",
    "print(\"Mean absolute error: \" + str(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean squared error: \" + str(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Root Mean Squared Error:', +(np.sqrt(mean_qerror)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95340262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_val = [] # to store values for different k \n",
    "\n",
    "# n_components = range(1,20)\n",
    "\n",
    "# train_accuracy = np.empty(len(n_components)\n",
    "# validation_accuracy = np.empty(len(n_components))\n",
    "\n",
    "# for K in range (n_components): \n",
    "#     K = K+1\n",
    "#     model = neighbors.KNeighborsRegressor(n_neighbors=K)\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "       \n",
    "#     y_pred_train = model.predict(X_train)\n",
    "#     y_pred_validate = model.predict(X_validate)\n",
    "    \n",
    "#     train_accuracy[K] = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "#     validation_accuracy[K] =metrics.mean_squared_error(y_validate, y_pred_validate)\n",
    "\n",
    "#     #error = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    \n",
    "# plt.plot(n_components, validation_accuracy, label='Validation Set MSE')\n",
    "# plt.plot(n_components, train_accuracy, label='Training Set MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c7b56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.drop('pca_df', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5030930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the accuracy score \n",
    "\n",
    "# acc_score = r2_score(y_test, y_prediction)\n",
    "\n",
    "# print ('r2 score:', acc_score)\n",
    "\n",
    "# mean_qerror = mean_square_error(y_test, y_prediction)\n",
    "\n",
    "# print('mean square error:', mean_qerror)\n",
    "\n",
    "# root_mean_qerror = np.sqrt(mean_qerror)\n",
    "\n",
    "# print('root mean square error:', root_mean_qerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af65f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64ecd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# X = \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = yr, shuffle = True, random_state =42)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# y_predict = model.predict(X_test)\n",
    "\n",
    "# train_Acc = model.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.3, stratify = y, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "# #creating the linear regression \n",
    "# model = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "# #predicting the outcome based on the regression model \n",
    "# y_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "# #checking the accuracy of the training data \n",
    "# train_acc = model.score(X_train,y_train)\n",
    "\n",
    "# print('Train Accuracy:', train_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfa0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['Left-Lateral-Ventricle','Left-Inf-Lat-Vent', 'Left-Cerebellum-White-Matter', 'Left-Cerebellum-Cortex', 'Left-Thalamus', 'Left-Caudate', 'Left-Putamen', 'Left-Pallidum', '3rd-Ventricle', '4th-Ventricle', 'Brain-Stem', 'Left-Hippocampus', 'Left-Amygdala', 'CSF', 'Left-Accumbens-area', 'Left-VentralDC', 'Left-VentralDC', 'Left-choroid-plexus', 'Right-Lateral-Ventricle', 'Right-Inf-Lat-Vent', 'Right-Cerebellum-White-Matter', 'Right-Cerebellum-Cortex', 'Right-Thalamus', 'Right-Caudate', 'Right-Putamen', 'Right-Pallidum', 'Right-Hippocampus', 'Right-Amygdala', 'Right-Accumbens-area', 'Right-VentralDC','Right-vessel', 'Right-choroid-plexus', '5th-Ventricle', 'WM-hypointensities', 'Left-WM-hypointensities', 'Right-WM-hypointensities', 'non-WM-hypointensities', 'Left-non-WM-hypointensities', 'Right-non-WM-hypointensities', 'Optic-Chiasm', 'CC_Posterior', 'CC_Mid_Posterior', 'CC_Central', 'CC_Mid_Anterior', 'CC_Anterior', 'BrainSegVol', 'BrainSegVolNotVent', 'lhCortexVol', 'rhCortexVol', 'CortexVol', 'lhCerebralWhiteMatterVol', 'rhCerebralWhiteMatterVol', 'CerebralWhiteMatterVol', 'SubCortGrayVol', 'TotalGrayVol', 'SupraTentorialVol', 'SupraTentorialVolNotVent', 'MaskVol', 'BrainSegVol-to-eTIV', 'MaskVol-to-eTIV', 'lhSurfaceHoles', 'rhSurfaceHoles', 'SurfaceHoles', 'EstimatedTotalIntraCranialVol', 'lh_bankssts_thickness', 'lh_caudalanteriorcingulate_thickness', 'lh_caudalmiddlefrontal_thickness', 'lh_cuneus_thickness', 'lh_entorhinal_thickness', 'lh_fusiform_thickness', 'lh_inferiorparietal_thickness', 'lh_inferiortemporal_thickness', 'lh_isthmuscingulate_thickness', 'lh_lateraloccipital_thickness', 'lh_lateralorbitofrontal_thickness', 'lh_lingual_thickness', 'lh_medialorbitofrontal_thickness', 'lh_middletemporal_thickness', 'lh_parahippocampal_thickness', 'lh_paracentral_thickness', 'lh_parsopercularis_thickness', 'lh_parsorbitalis_thickness', 'lh_parstriangularis_thickness', 'lh_pericalcarine_thickness', 'lh_postcentral_thickness', 'lh_posteriorcingulate_thickness', 'lh_precentral_thickness', 'lh_precuneus_thickness', 'lh_rostralanteriorcingulate_thickness','lh_rostralmiddlefrontal_thickness', 'lh_superiorfrontal_thickness', 'lh_superiorparietal_thickness', 'lh_superiortemporal_thickness', 'lh_supramarginal_thickness', 'lh_frontalpole_thickness', 'lh_temporalpole_thickness', 'lh_transversetemporal_thickness', 'lh_insula_thickness', 'lh_MeanThickness_thickness', 'BrainSegVolNotVent.1', 'eTIV', 'rh_bankssts_thickness', 'rh_caudalanteriorcingulate_thickness', 'rh_caudalmiddlefrontal_thickness', 'rh_cuneus_thickness', 'rh_entorhinal_thickness', 'rh_fusiform_thickness', 'rh_inferiorparietal_thickness', 'rh_inferiortemporal_thickness', 'rh_isthmuscingulate_thickness', 'rh_lateraloccipital_thickness', 'rh_lateralorbitofrontal_thickness', 'rh_lingual_thickness', 'rh_medialorbitofrontal_thickness', 'rh_middletemporal_thickness', 'rh_parahippocampal_thickness', 'rh_paracentral_thickness', 'rh_parsopercularis_thickness', 'rh_parsorbitalis_thickness', 'rh_parstriangularis_thickness', 'rh_pericalcarine_thickness', 'rh_postcentral_thickness', 'rh_posteriorcingulate_thickness', 'rh_precentral_thickness', 'rh_precuneus_thickness', 'rh_rostralanteriorcingulate_thickness', 'rh_rostralmiddlefrontal_thickness', 'rh_superiorfrontal_thickness', 'rh_superiorparietal_thickness', 'rh_superiortemporal_thickness', 'rh_supramarginal_thickness', 'rh_frontalpole_thickness', 'rh_temporalpole_thickness', 'rh_transversetemporal_thickness', 'rh_insula_thickness', 'rh_MeanThickness_thickness', 'BrainSegVolNotVent.2', 'eTIV.1', 'Age', 'dataset']\n",
    "\n",
    "#separating out the features\n",
    "X = data.loc[:, features].values\n",
    "\n",
    "#separating out thetarget \n",
    "y = data.loc[:,['Age']].values\n",
    "\n",
    "#standardizing the features\n",
    "\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b51fb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "\n",
    "pca = PCA(n_components)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(data= principalComponents, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4', 'principal component 5'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, data[['Age']]], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8149d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (700, 100) (700,)\n",
      "Test: (300, 100) (700,)\n"
     ]
    }
   ],
   "source": [
    "# #Generate regression dataset #fix (n_sample and n_features)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100, n_informative =10, noise =0.1, random_state =1)\n",
    "\n",
    "# #split into train and test sets \n",
    "# X_train, X_test, y_train, y_test = train_test_split (X,y, test_size = 0.30, random_state=1)\n",
    "\n",
    "\n",
    "# print('Train:', X_train.shape, y_train.shape)\n",
    "# print('Test:', X_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature selection \n",
    "# def select_features(X_train, y_train, X_test):\n",
    "    \n",
    "#     #configure to select all features \n",
    "#     fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    \n",
    "#     #learn relationship from training data \n",
    "#     fs.fit(X_train, y_train)\n",
    "    \n",
    "#     #transform train input data \n",
    "#     X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "#     #transfrom test input data \n",
    "#     X_test_fs = fs.transform(X_test)\n",
    "    \n",
    "#     return X_train_fs, X_test_fs, fs \n",
    "\n",
    "\n",
    "# #load dataset \n",
    "\n",
    "# X,y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise = 0.1, random_state=1)\n",
    "\n",
    "# #split into train and test sets \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state =1)\n",
    "\n",
    "# #feature selection\n",
    "# X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# #scores for each features\n",
    "\n",
    "# for i in range(len(fs.scores_)):\n",
    "#     print('Feature %d: %f' %(i, fs.scores_[i]))\n",
    "    \n",
    "# #plot scores \n",
    "\n",
    "# plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_features(X_train, y_train, X_test):\n",
    "    \n",
    "#     #Configure to select all features \n",
    "#     fs = SelectKBest(score_func=mutual_into_regression, k='all')\n",
    "    \n",
    "#     #learn the relationship from training data \n",
    "#     fs.fit(X_train, y_train)\n",
    "    \n",
    "#     #transform train input data \n",
    "#     X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "#     #transform test input data \n",
    "#     X_test_fs = fs.transform(X_test)\n",
    "#     return X_train_fs, X_test_fs, fs \n",
    "\n",
    "# #load the dataset \n",
    "\n",
    "# X,y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise = 0.1, random_state=1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a7d479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop_duplicates(inplace=True)\n",
    "\n",
    "# indep = 'Volumetric_features'\n",
    "\n",
    "# Xdata = data.drop([indep],axis=1)\n",
    "# Xr = Xdata \n",
    "# yr = data[indep]\n",
    "\n",
    "\n",
    "# x_train,x_test, y_train, y_test = train_test_split(Xr,yr,test_size = 0.30, stratify = yr, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "# model = Pipeline([('scaler', StandardScaler()), ('classifier', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "\n",
    "# mfit = model.fit(x_train, y_train)\n",
    "# ypred = mfit.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6354c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
